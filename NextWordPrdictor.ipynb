{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwGwLgbzqMQ6mw4tt4zic1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishaliMJ/Deep-Learning/blob/main/NextWordPrdictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_tgc1AFcyj4s"
      },
      "outputs": [],
      "source": [
        "doc=\"\"\"Cairo is the capital and largest city of Egypt And the\n",
        "Cairo Governorate. It is home to more than 10.5\n",
        "Million people. It is also part of the largest urban\n",
        "Agglomeration in Africa, the Arab World , and the\n",
        "Middle East. The Greater Cairo metropolitan area is one\n",
        "Of the largest in the world by population with over\n",
        "22 million people . Areas of what would become Cairo were\n",
        "Inhabited from pre - dynastic and early - dynastic ancient\n",
        "Egypt c. 6000 years ago , as the Giza pyramid complex\n",
        "And the ancient citie\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "VxHaAaDwy31L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n"
      ],
      "metadata": {
        "id": "4Zzbn0npy-gh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([doc])"
      ],
      "metadata": {
        "id": "BzNMzX_azNnL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaM_Hk3jzWZr",
        "outputId": "71291e36-32c3-45fc-80b7-50b18e9db54c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenList=[]\n",
        "for sentence in doc.split(\"\\n\"):\n",
        "  tokenize_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for index in range(1,len(tokenize_sentence)):\n",
        "    tokenList.append(tokenize_sentence[:index+1])\n",
        "\n",
        "tokenList\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdUA-BnIzbfd",
        "outputId": "e0c690ea-c342-4c1c-f7b6-7096bead2daa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 4],\n",
              " [3, 4, 1],\n",
              " [3, 4, 1, 15],\n",
              " [3, 4, 1, 15, 2],\n",
              " [3, 4, 1, 15, 2, 6],\n",
              " [3, 4, 1, 15, 2, 6, 16],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7, 2],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7, 2, 1],\n",
              " [3, 17],\n",
              " [3, 17, 8],\n",
              " [3, 17, 8, 4],\n",
              " [3, 17, 8, 4, 18],\n",
              " [3, 17, 8, 4, 18, 19],\n",
              " [3, 17, 8, 4, 18, 19, 20],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21, 22],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21, 22, 23],\n",
              " [9, 10],\n",
              " [9, 10, 8],\n",
              " [9, 10, 8, 4],\n",
              " [9, 10, 8, 4, 24],\n",
              " [9, 10, 8, 4, 24, 25],\n",
              " [9, 10, 8, 4, 24, 25, 5],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1, 6],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1, 6, 26],\n",
              " [27, 11],\n",
              " [27, 11, 28],\n",
              " [27, 11, 28, 1],\n",
              " [27, 11, 28, 1, 29],\n",
              " [27, 11, 28, 1, 29, 12],\n",
              " [27, 11, 28, 1, 29, 12, 2],\n",
              " [27, 11, 28, 1, 29, 12, 2, 1],\n",
              " [30, 31],\n",
              " [30, 31, 1],\n",
              " [30, 31, 1, 32],\n",
              " [30, 31, 1, 32, 3],\n",
              " [30, 31, 1, 32, 3, 33],\n",
              " [30, 31, 1, 32, 3, 33, 34],\n",
              " [30, 31, 1, 32, 3, 33, 34, 4],\n",
              " [30, 31, 1, 32, 3, 33, 34, 4, 35],\n",
              " [5, 1],\n",
              " [5, 1, 6],\n",
              " [5, 1, 6, 11],\n",
              " [5, 1, 6, 11, 1],\n",
              " [5, 1, 6, 11, 1, 12],\n",
              " [5, 1, 6, 11, 1, 12, 36],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37, 38],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37, 38, 39],\n",
              " [40, 9],\n",
              " [40, 9, 10],\n",
              " [40, 9, 10, 41],\n",
              " [40, 9, 10, 41, 5],\n",
              " [40, 9, 10, 41, 5, 42],\n",
              " [40, 9, 10, 41, 5, 42, 43],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44, 3],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44, 3, 45],\n",
              " [46, 47],\n",
              " [46, 47, 48],\n",
              " [46, 47, 48, 13],\n",
              " [46, 47, 48, 13, 2],\n",
              " [46, 47, 48, 13, 2, 49],\n",
              " [46, 47, 48, 13, 2, 49, 13],\n",
              " [46, 47, 48, 13, 2, 49, 13, 14],\n",
              " [7, 50],\n",
              " [7, 50, 51],\n",
              " [7, 50, 51, 52],\n",
              " [7, 50, 51, 52, 53],\n",
              " [7, 50, 51, 52, 53, 54],\n",
              " [7, 50, 51, 52, 53, 54, 1],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55, 56],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55, 56, 57],\n",
              " [2, 1],\n",
              " [2, 1, 14],\n",
              " [2, 1, 14, 58]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen=max([len(x) for x in tokenList])\n",
        "maxLen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaTNux682yjK",
        "outputId": "5947d2db-ce20-4bc6-a29c-0361b8af8748"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "paddedInputSeq=pad_sequences(tokenList,maxlen=maxLen,padding=\"pre\")\n",
        "\n",
        "paddedInputSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGy5I3JX3UxR",
        "outputId": "625948c4-7e3b-493f-e4fd-cbcff510be4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3,  4,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  3,  4,  1, 15],\n",
              "       [ 0,  0,  0,  0,  0,  0,  3,  4,  1, 15,  2],\n",
              "       [ 0,  0,  0,  0,  0,  3,  4,  1, 15,  2,  6],\n",
              "       [ 0,  0,  0,  0,  3,  4,  1, 15,  2,  6, 16],\n",
              "       [ 0,  0,  0,  3,  4,  1, 15,  2,  6, 16,  5],\n",
              "       [ 0,  0,  3,  4,  1, 15,  2,  6, 16,  5,  7],\n",
              "       [ 0,  3,  4,  1, 15,  2,  6, 16,  5,  7,  2],\n",
              "       [ 3,  4,  1, 15,  2,  6, 16,  5,  7,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3, 17],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3, 17,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  3, 17,  8,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  3, 17,  8,  4, 18],\n",
              "       [ 0,  0,  0,  0,  0,  3, 17,  8,  4, 18, 19],\n",
              "       [ 0,  0,  0,  0,  3, 17,  8,  4, 18, 19, 20],\n",
              "       [ 0,  0,  0,  3, 17,  8,  4, 18, 19, 20, 21],\n",
              "       [ 0,  0,  3, 17,  8,  4, 18, 19, 20, 21, 22],\n",
              "       [ 0,  3, 17,  8,  4, 18, 19, 20, 21, 22, 23],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9, 10,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  9, 10,  8,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  9, 10,  8,  4, 24],\n",
              "       [ 0,  0,  0,  0,  0,  9, 10,  8,  4, 24, 25],\n",
              "       [ 0,  0,  0,  0,  9, 10,  8,  4, 24, 25,  5],\n",
              "       [ 0,  0,  0,  9, 10,  8,  4, 24, 25,  5,  1],\n",
              "       [ 0,  0,  9, 10,  8,  4, 24, 25,  5,  1,  6],\n",
              "       [ 0,  9, 10,  8,  4, 24, 25,  5,  1,  6, 26],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 27, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 27, 11, 28],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 27, 11, 28,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0, 27, 11, 28,  1, 29],\n",
              "       [ 0,  0,  0,  0,  0, 27, 11, 28,  1, 29, 12],\n",
              "       [ 0,  0,  0,  0, 27, 11, 28,  1, 29, 12,  2],\n",
              "       [ 0,  0,  0, 27, 11, 28,  1, 29, 12,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 30, 31],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 30, 31,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 30, 31,  1, 32],\n",
              "       [ 0,  0,  0,  0,  0,  0, 30, 31,  1, 32,  3],\n",
              "       [ 0,  0,  0,  0,  0, 30, 31,  1, 32,  3, 33],\n",
              "       [ 0,  0,  0,  0, 30, 31,  1, 32,  3, 33, 34],\n",
              "       [ 0,  0,  0, 30, 31,  1, 32,  3, 33, 34,  4],\n",
              "       [ 0,  0, 30, 31,  1, 32,  3, 33, 34,  4, 35],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1,  6],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  5,  1,  6, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  5,  1,  6, 11,  1],\n",
              "       [ 0,  0,  0,  0,  0,  5,  1,  6, 11,  1, 12],\n",
              "       [ 0,  0,  0,  0,  5,  1,  6, 11,  1, 12, 36],\n",
              "       [ 0,  0,  0,  5,  1,  6, 11,  1, 12, 36, 37],\n",
              "       [ 0,  0,  5,  1,  6, 11,  1, 12, 36, 37, 38],\n",
              "       [ 0,  5,  1,  6, 11,  1, 12, 36, 37, 38, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40,  9],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 40,  9, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 40,  9, 10, 41],\n",
              "       [ 0,  0,  0,  0,  0,  0, 40,  9, 10, 41,  5],\n",
              "       [ 0,  0,  0,  0,  0, 40,  9, 10, 41,  5, 42],\n",
              "       [ 0,  0,  0,  0, 40,  9, 10, 41,  5, 42, 43],\n",
              "       [ 0,  0,  0, 40,  9, 10, 41,  5, 42, 43, 44],\n",
              "       [ 0,  0, 40,  9, 10, 41,  5, 42, 43, 44,  3],\n",
              "       [ 0, 40,  9, 10, 41,  5, 42, 43, 44,  3, 45],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 46, 47],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 46, 47, 48],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 46, 47, 48, 13],\n",
              "       [ 0,  0,  0,  0,  0,  0, 46, 47, 48, 13,  2],\n",
              "       [ 0,  0,  0,  0,  0, 46, 47, 48, 13,  2, 49],\n",
              "       [ 0,  0,  0,  0, 46, 47, 48, 13,  2, 49, 13],\n",
              "       [ 0,  0,  0, 46, 47, 48, 13,  2, 49, 13, 14],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  7, 50],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  7, 50, 51],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  7, 50, 51, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  7, 50, 51, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  7, 50, 51, 52, 53, 54],\n",
              "       [ 0,  0,  0,  0,  7, 50, 51, 52, 53, 54,  1],\n",
              "       [ 0,  0,  0,  7, 50, 51, 52, 53, 54,  1, 55],\n",
              "       [ 0,  0,  7, 50, 51, 52, 53, 54,  1, 55, 56],\n",
              "       [ 0,  7, 50, 51, 52, 53, 54,  1, 55, 56, 57],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  1, 14],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  2,  1, 14, 58]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputSeq=paddedInputSeq[:,:-1]\n",
        "\n",
        "inputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxgJjr7T4Qe4",
        "outputId": "b2284493-18e6-42e0-8e72-a4827502be55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputSeq=paddedInputSeq[:,-1]\n",
        "\n",
        "outputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdLzx0W34n0G",
        "outputId": "1a2775e5-82bb-436c-a6b9-e6183f7b7f19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "outputSeq=to_categorical(outputSeq,num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "outputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAZWtSrN6V0q",
        "outputId": "8789899e-9d15-4257-91d1-4f3d79644893"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vIn9HAaSngZ",
        "outputId": "e684bd4e-c942-41df-8bc7-b19f441fb0ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM, Dense,Dropout\n",
        "import keras\n",
        "model=Sequential()\n",
        "model.add(keras.Input(shape=(maxLen,)))\n",
        "#model.add(Embedding(len(tokenizer.word_index)+1,128,input_length=maxLen-1),input_shape=maxLen-1)\n",
        "model.add(Embedding(len(tokenizer.word_index)+1,128,input_length=maxLen-1))\n",
        "\n",
        "#model.add(LSTM(128,return_sequences=True))\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(len(tokenizer.word_index)+1,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "xesvB8FL-9MG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "y5vPHhA78Bnc"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "1o8lifjy8MGy",
        "outputId": "b1f24296-daef-44c5-b8f0-5c0dc4fc4149"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_12 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m7,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)             │         \u001b[38;5;34m7,611\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,611</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m146,747\u001b[0m (573.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,747</span> (573.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m146,747\u001b[0m (573.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,747</span> (573.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "model.fit(inputSeq, outputSeq, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdm73f1l95Tz",
        "outputId": "23aacac8-e4c9-4adb-a9b0-7d1a18eda763"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0266 - loss: 4.0790  \n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1250 - loss: 4.0578\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1094 - loss: 4.0356\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.9938\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1367 - loss: 3.9265\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1562 - loss: 3.8271\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1367 - loss: 3.7641\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1562 - loss: 3.6683\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1406 - loss: 3.6958\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1328 - loss: 3.7645\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1406 - loss: 3.6841\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1094 - loss: 3.7113\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.6929\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1250 - loss: 3.6056\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1094 - loss: 3.6287\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1453 - loss: 3.5748\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1633 - loss: 3.5106\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1633 - loss: 3.5142\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.5084\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1789 - loss: 3.4533\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1906 - loss: 3.3355\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1836 - loss: 3.3445\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1586 - loss: 3.3278\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2070 - loss: 3.2203\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2297 - loss: 3.1430\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2211 - loss: 3.0772\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2352 - loss: 3.0295\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2484 - loss: 2.9252\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2578 - loss: 2.8820\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2805 - loss: 2.7614\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2305 - loss: 2.6256\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3562 - loss: 2.4647\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3438 - loss: 2.5155\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4109 - loss: 2.3780\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2945 - loss: 2.4088\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4266 - loss: 2.1972\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4359 - loss: 2.2551\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4094 - loss: 2.1559\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4969 - loss: 1.9405\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5273 - loss: 1.8670\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5539 - loss: 1.8509\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4187 - loss: 1.9323\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5203 - loss: 1.8028\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5922 - loss: 1.7764\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6031 - loss: 1.6170\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5820 - loss: 1.6035\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6453 - loss: 1.4800\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6047 - loss: 1.5493\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5445 - loss: 1.6296\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6836 - loss: 1.4056\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6375 - loss: 1.4433\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7086 - loss: 1.3357 \n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6031 - loss: 1.2745\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6883 - loss: 1.2936\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6430 - loss: 1.3418\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5961 - loss: 1.3206\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7234 - loss: 1.2022 \n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7523 - loss: 1.1560\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6742 - loss: 1.1865\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7336 - loss: 1.1304\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6961 - loss: 1.1170\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6977 - loss: 1.0827\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8062 - loss: 1.0567\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8547 - loss: 0.8920\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8797 - loss: 0.9380\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8023 - loss: 0.9396\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7930 - loss: 0.9842\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7984 - loss: 0.9598\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7852 - loss: 0.9140\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8828 - loss: 0.8191\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8398 - loss: 0.7952\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8281 - loss: 0.7419\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8898 - loss: 0.7549\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8594 - loss: 0.7438\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8750 - loss: 0.8128\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8625 - loss: 0.7732\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8906 - loss: 0.6524\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8891 - loss: 0.7242\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8891 - loss: 0.7113\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8836 - loss: 0.6555\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8906 - loss: 0.6662\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9250 - loss: 0.6569\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8562 - loss: 0.6430\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9336 - loss: 0.5967\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9391 - loss: 0.6029\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9180 - loss: 0.6003\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9367 - loss: 0.5263\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9336 - loss: 0.5579\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9336 - loss: 0.5649\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9719 - loss: 0.4924\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9195 - loss: 0.5086\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9617 - loss: 0.4846\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9656 - loss: 0.4571\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9312 - loss: 0.4824\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.4586\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9250 - loss: 0.4549\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9719 - loss: 0.4084\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.3908\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9758 - loss: 0.3942\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9695 - loss: 0.4429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7935b061fcb0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Testing\n",
        "testData=\"Inhabited\"\n",
        "\n",
        "for i in range(5):\n",
        "  #Tokenize data\n",
        "  tokenText=tokenizer.texts_to_sequences([testData])[0]\n",
        "\n",
        "  #Padding\n",
        "  padText=pad_sequences([tokenText],maxlen=maxLen,padding=\"pre\")\n",
        "\n",
        "  #padText\n",
        "\n",
        "  #Predict Result\n",
        "  predictResultPos=np.argmax(model.predict(padText))\n",
        "\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==predictResultPos:\n",
        "      testData=testData + \" \" + word\n",
        "      print(testData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu02yqmhVyx6",
        "outputId": "fbc4fa34-6763-4bfe-a83f-a75392eee58e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Inhabited from\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Inhabited from pre\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Inhabited from pre dynastic\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Inhabited from pre dynastic and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Inhabited from pre dynastic and early\n"
          ]
        }
      ]
    }
  ]
}