{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOENHL0Vh5aNF7ta6OkZJK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VaishaliMJ/Deep-Learning/blob/main/NextWordPrdictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_tgc1AFcyj4s"
      },
      "outputs": [],
      "source": [
        "doc=\"\"\"Cairo is the capital and largest city of Egypt And the\n",
        "Cairo Governorate. It is home to more than 10.5\n",
        "Million people. It is also part of the largest urban\n",
        "Agglomeration in Africa, the Arab World , and the\n",
        "Middle East. The Greater Cairo metropolitan area is one\n",
        "Of the largest in the world by population with over\n",
        "22 million people . Areas of what would become Cairo were\n",
        "Inhabited from pre - dynastic and early - dynastic ancient\n",
        "Egypt c. 6000 years ago , as the Giza pyramid complex\n",
        "And the ancient citie\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "id": "VxHaAaDwy31L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n"
      ],
      "metadata": {
        "id": "4Zzbn0npy-gh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([doc])"
      ],
      "metadata": {
        "id": "BzNMzX_azNnL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaM_Hk3jzWZr",
        "outputId": "71291e36-32c3-45fc-80b7-50b18e9db54c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenList=[]\n",
        "for sentence in doc.split(\"\\n\"):\n",
        "  tokenize_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for index in range(1,len(tokenize_sentence)):\n",
        "    tokenList.append(tokenize_sentence[:index+1])\n",
        "\n",
        "tokenList\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdUA-BnIzbfd",
        "outputId": "e0c690ea-c342-4c1c-f7b6-7096bead2daa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 4],\n",
              " [3, 4, 1],\n",
              " [3, 4, 1, 15],\n",
              " [3, 4, 1, 15, 2],\n",
              " [3, 4, 1, 15, 2, 6],\n",
              " [3, 4, 1, 15, 2, 6, 16],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7, 2],\n",
              " [3, 4, 1, 15, 2, 6, 16, 5, 7, 2, 1],\n",
              " [3, 17],\n",
              " [3, 17, 8],\n",
              " [3, 17, 8, 4],\n",
              " [3, 17, 8, 4, 18],\n",
              " [3, 17, 8, 4, 18, 19],\n",
              " [3, 17, 8, 4, 18, 19, 20],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21, 22],\n",
              " [3, 17, 8, 4, 18, 19, 20, 21, 22, 23],\n",
              " [9, 10],\n",
              " [9, 10, 8],\n",
              " [9, 10, 8, 4],\n",
              " [9, 10, 8, 4, 24],\n",
              " [9, 10, 8, 4, 24, 25],\n",
              " [9, 10, 8, 4, 24, 25, 5],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1, 6],\n",
              " [9, 10, 8, 4, 24, 25, 5, 1, 6, 26],\n",
              " [27, 11],\n",
              " [27, 11, 28],\n",
              " [27, 11, 28, 1],\n",
              " [27, 11, 28, 1, 29],\n",
              " [27, 11, 28, 1, 29, 12],\n",
              " [27, 11, 28, 1, 29, 12, 2],\n",
              " [27, 11, 28, 1, 29, 12, 2, 1],\n",
              " [30, 31],\n",
              " [30, 31, 1],\n",
              " [30, 31, 1, 32],\n",
              " [30, 31, 1, 32, 3],\n",
              " [30, 31, 1, 32, 3, 33],\n",
              " [30, 31, 1, 32, 3, 33, 34],\n",
              " [30, 31, 1, 32, 3, 33, 34, 4],\n",
              " [30, 31, 1, 32, 3, 33, 34, 4, 35],\n",
              " [5, 1],\n",
              " [5, 1, 6],\n",
              " [5, 1, 6, 11],\n",
              " [5, 1, 6, 11, 1],\n",
              " [5, 1, 6, 11, 1, 12],\n",
              " [5, 1, 6, 11, 1, 12, 36],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37, 38],\n",
              " [5, 1, 6, 11, 1, 12, 36, 37, 38, 39],\n",
              " [40, 9],\n",
              " [40, 9, 10],\n",
              " [40, 9, 10, 41],\n",
              " [40, 9, 10, 41, 5],\n",
              " [40, 9, 10, 41, 5, 42],\n",
              " [40, 9, 10, 41, 5, 42, 43],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44, 3],\n",
              " [40, 9, 10, 41, 5, 42, 43, 44, 3, 45],\n",
              " [46, 47],\n",
              " [46, 47, 48],\n",
              " [46, 47, 48, 13],\n",
              " [46, 47, 48, 13, 2],\n",
              " [46, 47, 48, 13, 2, 49],\n",
              " [46, 47, 48, 13, 2, 49, 13],\n",
              " [46, 47, 48, 13, 2, 49, 13, 14],\n",
              " [7, 50],\n",
              " [7, 50, 51],\n",
              " [7, 50, 51, 52],\n",
              " [7, 50, 51, 52, 53],\n",
              " [7, 50, 51, 52, 53, 54],\n",
              " [7, 50, 51, 52, 53, 54, 1],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55, 56],\n",
              " [7, 50, 51, 52, 53, 54, 1, 55, 56, 57],\n",
              " [2, 1],\n",
              " [2, 1, 14],\n",
              " [2, 1, 14, 58]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen=max([len(x) for x in tokenList])\n",
        "maxLen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaTNux682yjK",
        "outputId": "5947d2db-ce20-4bc6-a29c-0361b8af8748"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "paddedInputSeq=pad_sequences(tokenList,maxlen=maxLen,padding=\"pre\")\n",
        "\n",
        "paddedInputSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGy5I3JX3UxR",
        "outputId": "625948c4-7e3b-493f-e4fd-cbcff510be4c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3,  4,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  3,  4,  1, 15],\n",
              "       [ 0,  0,  0,  0,  0,  0,  3,  4,  1, 15,  2],\n",
              "       [ 0,  0,  0,  0,  0,  3,  4,  1, 15,  2,  6],\n",
              "       [ 0,  0,  0,  0,  3,  4,  1, 15,  2,  6, 16],\n",
              "       [ 0,  0,  0,  3,  4,  1, 15,  2,  6, 16,  5],\n",
              "       [ 0,  0,  3,  4,  1, 15,  2,  6, 16,  5,  7],\n",
              "       [ 0,  3,  4,  1, 15,  2,  6, 16,  5,  7,  2],\n",
              "       [ 3,  4,  1, 15,  2,  6, 16,  5,  7,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3, 17],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3, 17,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  3, 17,  8,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  3, 17,  8,  4, 18],\n",
              "       [ 0,  0,  0,  0,  0,  3, 17,  8,  4, 18, 19],\n",
              "       [ 0,  0,  0,  0,  3, 17,  8,  4, 18, 19, 20],\n",
              "       [ 0,  0,  0,  3, 17,  8,  4, 18, 19, 20, 21],\n",
              "       [ 0,  0,  3, 17,  8,  4, 18, 19, 20, 21, 22],\n",
              "       [ 0,  3, 17,  8,  4, 18, 19, 20, 21, 22, 23],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9, 10,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  9, 10,  8,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  9, 10,  8,  4, 24],\n",
              "       [ 0,  0,  0,  0,  0,  9, 10,  8,  4, 24, 25],\n",
              "       [ 0,  0,  0,  0,  9, 10,  8,  4, 24, 25,  5],\n",
              "       [ 0,  0,  0,  9, 10,  8,  4, 24, 25,  5,  1],\n",
              "       [ 0,  0,  9, 10,  8,  4, 24, 25,  5,  1,  6],\n",
              "       [ 0,  9, 10,  8,  4, 24, 25,  5,  1,  6, 26],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 27, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 27, 11, 28],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 27, 11, 28,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0, 27, 11, 28,  1, 29],\n",
              "       [ 0,  0,  0,  0,  0, 27, 11, 28,  1, 29, 12],\n",
              "       [ 0,  0,  0,  0, 27, 11, 28,  1, 29, 12,  2],\n",
              "       [ 0,  0,  0, 27, 11, 28,  1, 29, 12,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 30, 31],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 30, 31,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 30, 31,  1, 32],\n",
              "       [ 0,  0,  0,  0,  0,  0, 30, 31,  1, 32,  3],\n",
              "       [ 0,  0,  0,  0,  0, 30, 31,  1, 32,  3, 33],\n",
              "       [ 0,  0,  0,  0, 30, 31,  1, 32,  3, 33, 34],\n",
              "       [ 0,  0,  0, 30, 31,  1, 32,  3, 33, 34,  4],\n",
              "       [ 0,  0, 30, 31,  1, 32,  3, 33, 34,  4, 35],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  5,  1,  6],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  5,  1,  6, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  5,  1,  6, 11,  1],\n",
              "       [ 0,  0,  0,  0,  0,  5,  1,  6, 11,  1, 12],\n",
              "       [ 0,  0,  0,  0,  5,  1,  6, 11,  1, 12, 36],\n",
              "       [ 0,  0,  0,  5,  1,  6, 11,  1, 12, 36, 37],\n",
              "       [ 0,  0,  5,  1,  6, 11,  1, 12, 36, 37, 38],\n",
              "       [ 0,  5,  1,  6, 11,  1, 12, 36, 37, 38, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 40,  9],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 40,  9, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 40,  9, 10, 41],\n",
              "       [ 0,  0,  0,  0,  0,  0, 40,  9, 10, 41,  5],\n",
              "       [ 0,  0,  0,  0,  0, 40,  9, 10, 41,  5, 42],\n",
              "       [ 0,  0,  0,  0, 40,  9, 10, 41,  5, 42, 43],\n",
              "       [ 0,  0,  0, 40,  9, 10, 41,  5, 42, 43, 44],\n",
              "       [ 0,  0, 40,  9, 10, 41,  5, 42, 43, 44,  3],\n",
              "       [ 0, 40,  9, 10, 41,  5, 42, 43, 44,  3, 45],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 46, 47],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 46, 47, 48],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 46, 47, 48, 13],\n",
              "       [ 0,  0,  0,  0,  0,  0, 46, 47, 48, 13,  2],\n",
              "       [ 0,  0,  0,  0,  0, 46, 47, 48, 13,  2, 49],\n",
              "       [ 0,  0,  0,  0, 46, 47, 48, 13,  2, 49, 13],\n",
              "       [ 0,  0,  0, 46, 47, 48, 13,  2, 49, 13, 14],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  7, 50],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  7, 50, 51],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  7, 50, 51, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  7, 50, 51, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  7, 50, 51, 52, 53, 54],\n",
              "       [ 0,  0,  0,  0,  7, 50, 51, 52, 53, 54,  1],\n",
              "       [ 0,  0,  0,  7, 50, 51, 52, 53, 54,  1, 55],\n",
              "       [ 0,  0,  7, 50, 51, 52, 53, 54,  1, 55, 56],\n",
              "       [ 0,  7, 50, 51, 52, 53, 54,  1, 55, 56, 57],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  1, 14],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  2,  1, 14, 58]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputSeq=paddedInputSeq[:,:-1]\n",
        "\n",
        "inputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxgJjr7T4Qe4",
        "outputId": "b2284493-18e6-42e0-8e72-a4827502be55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputSeq=paddedInputSeq[:,-1]\n",
        "\n",
        "outputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdLzx0W34n0G",
        "outputId": "1a2775e5-82bb-436c-a6b9-e6183f7b7f19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "outputSeq=to_categorical(outputSeq,num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "outputSeq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAZWtSrN6V0q",
        "outputId": "8789899e-9d15-4257-91d1-4f3d79644893"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 59)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vIn9HAaSngZ",
        "outputId": "e684bd4e-c942-41df-8bc7-b19f441fb0ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM, Dense\n",
        "import keras\n",
        "model=Sequential()\n",
        "model.add(keras.Input(shape=(maxLen,)))\n",
        "#model.add(Embedding(len(tokenizer.word_index)+1,128,input_length=maxLen-1),input_shape=maxLen-1)\n",
        "model.add(Embedding(len(tokenizer.word_index)+1,128,input_length=maxLen-1))\n",
        "\n",
        "#model.add(LSTM(128,return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(tokenizer.word_index)+1,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "xesvB8FL-9MG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "y5vPHhA78Bnc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "1o8lifjy8MGy",
        "outputId": "d31dc5ac-3edd-4b9e-d2da-083a7f29c129"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m7,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m)             │         \u001b[38;5;34m7,611\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,611</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m146,747\u001b[0m (573.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,747</span> (573.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m146,747\u001b[0m (573.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,747</span> (573.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "model.fit(inputSeq, outputSeq, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdm73f1l95Tz",
        "outputId": "6aea1941-ebb9-4c99-893e-5eda3e27c610"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0469 - loss: 4.0746\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1172 - loss: 4.0519\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1289 - loss: 4.0287\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1289 - loss: 3.9889\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1367 - loss: 3.9131\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1289 - loss: 3.7875\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1367 - loss: 3.7378\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1133 - loss: 3.7704\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.6923\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.6761\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1484 - loss: 3.5942\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1172 - loss: 3.5941\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1367 - loss: 3.5505\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1289 - loss: 3.4977\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1328 - loss: 3.4623\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1289 - loss: 3.4446\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1211 - loss: 3.3602\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1492 - loss: 3.3202\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1766 - loss: 3.2331\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1562 - loss: 3.2064\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1867 - loss: 3.0421\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1617 - loss: 3.0258\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2469 - loss: 2.9174\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2453 - loss: 2.8394\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2961 - loss: 2.7305\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3055 - loss: 2.5886\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2648 - loss: 2.5428\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3156 - loss: 2.3873\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3094 - loss: 2.3768\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3367 - loss: 2.2328\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3727 - loss: 2.2099\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4117 - loss: 2.1037\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4766 - loss: 2.0321\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5406 - loss: 1.8688 \n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5266 - loss: 1.8911\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5984 - loss: 1.7717\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5500 - loss: 1.7044\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6328 - loss: 1.6323\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6500 - loss: 1.6760\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6156 - loss: 1.5293\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6133 - loss: 1.4457\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7180 - loss: 1.4569\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7453 - loss: 1.3670\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7766 - loss: 1.2875\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7078 - loss: 1.3203\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7641 - loss: 1.2280\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7672 - loss: 1.2654\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8359 - loss: 1.1205\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8219 - loss: 1.1003\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8086 - loss: 1.0734\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7711 - loss: 1.0764\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8805 - loss: 0.9994\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8445 - loss: 0.9859\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8828 - loss: 0.9583\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8797 - loss: 0.9389\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8984 - loss: 0.9051\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9031 - loss: 0.8601\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8875 - loss: 0.8696\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8883 - loss: 0.8157\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8719 - loss: 0.8043\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8906 - loss: 0.7416\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9430 - loss: 0.7584\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8875 - loss: 0.7667\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9273 - loss: 0.7022\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9305 - loss: 0.6847\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9094 - loss: 0.6882\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9281 - loss: 0.6532 \n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9453 - loss: 0.6087\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9391 - loss: 0.5828\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9375 - loss: 0.5988\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9414 - loss: 0.5896\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9492 - loss: 0.5649\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9539 - loss: 0.5599\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9656 - loss: 0.5251\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.4868\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.5277\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9773 - loss: 0.4676\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9719 - loss: 0.4882\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9695 - loss: 0.4499\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9695 - loss: 0.4406\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9539 - loss: 0.4490\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9875 - loss: 0.4088\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9898 - loss: 0.4012\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.3814\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9797 - loss: 0.4149\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9797 - loss: 0.3859\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9820 - loss: 0.3599\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9820 - loss: 0.3636\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9898 - loss: 0.3424\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9937 - loss: 0.3314\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9719 - loss: 0.3336\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9836 - loss: 0.3046\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9719 - loss: 0.2984\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9898 - loss: 0.2927\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9898 - loss: 0.2903\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9898 - loss: 0.2897\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9820 - loss: 0.3052\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.2825\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9937 - loss: 0.2517\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9898 - loss: 0.2563\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7935b02c1940>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Testing\n",
        "testData=\"Inhabited\"\n",
        "\n",
        "for i in range(5):\n",
        "  #Tokenize data\n",
        "  tokenText=tokenizer.texts_to_sequences([testData])[0]\n",
        "\n",
        "  #Padding\n",
        "  padText=pad_sequences([tokenText],maxlen=maxLen,padding=\"pre\")\n",
        "\n",
        "  #padText\n",
        "\n",
        "  #Predict Result\n",
        "  predictResultPos=np.argmax(model.predict(padText))\n",
        "\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index==predictResultPos:\n",
        "      testData=testData + \" \" + word\n",
        "      print(testData)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu02yqmhVyx6",
        "outputId": "d31e482b-b38f-4a39-d459-cebcd03002f1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Inhabited from\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Inhabited from pre\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Inhabited from pre dynastic\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Inhabited from pre dynastic and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Inhabited from pre dynastic and early\n"
          ]
        }
      ]
    }
  ]
}